#!/usr/bin/env python3
"""
DBSCAN Clustering on SA-ConvLSTM Predictions
===========================================

This script applies DBSCAN clustering to the predictions generated by the SA-ConvLSTM model.
It can work with both test predictions and future forecasts from the model.

Author: Assistant
Date: 2024
"""

import os
# MUST be set BEFORE any other imports to suppress macOS warnings
os.environ['MallocStackLogging'] = '0'
os.environ['MALLOC_STACK_LOGGING'] = '0'

import sys
print(f"Using Python: {sys.executable}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from pathlib import Path
import imageio.v2 as imageio
from scipy.spatial import ConvexHull
import json
from datetime import datetime
import pandas as pd

# PyTorch imports for model loading
import torch
import torch.nn as nn
import xarray as xr
from skimage.transform import resize

# Import the SA-ConvLSTM model
sys.path.append(str(Path(__file__).parent / "regional-lstm"))
from sa_convlstm import SA_ConvLSTM_Model

# Set device
device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class Args:
    """Configuration class for SA-ConvLSTM model - matching the original"""
    def __init__(self):
        self.batch_size = 8
        self.gpu_num = 1
        self.img_size = 64
        self.num_layers = 1
        self.frame_num = 3
        self.input_dim = 1
        self.hidden_dim = 32
        self.learning_rate = 0.001
        self.epochs = 3
        self.patch_size = 4

def load_sa_convlstm_model(model_path, args):
    """Load the trained SA-ConvLSTM model"""
    print(f"Loading SA-ConvLSTM model from: {model_path}")
    
    model = SA_ConvLSTM_Model(args)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    print("Model loaded successfully!")
    return model

def apply_dbscan_to_prediction(prediction, timestamp_str, threshold=0.3, eps=3, min_samples=5, 
                             save_dir="dbscan_predictions", prediction_type="prediction"):
    """
    Apply DBSCAN clustering to a single prediction array.
    
    Args:
        prediction: 2D numpy array of predictions (height, width)
        timestamp_str: String representation of the timestamp
        threshold: Threshold for clustering (normalized scale)
        eps: DBSCAN eps parameter
        min_samples: DBSCAN min_samples parameter
        save_dir: Directory to save results
        prediction_type: Type of prediction ("test" or "forecast")
    """
    print(f"Applying DBSCAN to {prediction_type} for {timestamp_str}")
    
    # Ensure prediction is 2D
    if prediction.ndim > 2:
        prediction = prediction.squeeze()
    
    h, w = prediction.shape
    print(f"  Prediction shape: {h}x{w}")
    
    # Calculate average concentration
    avg_concentration = np.nanmean(prediction)
    print(f"  Average concentration: {avg_concentration:.6f}")
    
    # Create mask for clustering - use higher values
    valid_data_mask = ~np.isnan(prediction)
    threshold_mask = prediction > threshold
    combined_mask = valid_data_mask & threshold_mask
    
    filtered_indices = np.where(combined_mask)
    X = np.column_stack((filtered_indices[0], filtered_indices[1]))
    
    if len(X) == 0:
        print(f"  No data points above threshold {threshold}")
        # Create empty plot
        fig, ax = plt.subplots(figsize=(12, 8))
        img = ax.imshow(prediction, aspect='equal', cmap='viridis', origin='lower')
        ax.set_title(f"SA-ConvLSTM {prediction_type.title()} - No Clusters Found\n{timestamp_str}")
        ax.set_xlabel("Longitude Index")
        ax.set_ylabel("Latitude Index")
        plt.colorbar(img, ax=ax, label='Normalized Concentration')
        return fig, 0, 0

    # Apply DBSCAN
    db = DBSCAN(eps=eps, min_samples=min_samples).fit(X)
    labels = db.labels_

    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    n_noise = list(labels).count(-1)

    print(f"  Estimated clusters: {n_clusters}, Noise points: {n_noise}")

    # Create visualization
    fig, ax = plt.subplots(figsize=(12, 8))
    img = ax.imshow(prediction, aspect='equal', cmap='viridis', origin='lower')
    
    # Set colorbar
    cbar = plt.colorbar(img, ax=ax, label='Normalized Concentration')
    
    # Plot clusters
    unique_labels = set(labels)
    colors = [plt.cm.gist_ncar(each) for each in np.linspace(0, 1, len(unique_labels))]
    
    for k, col in zip(unique_labels, colors):
        if k == -1:
            col = [0, 0, 0, 1]  # Black for noise

        class_member_mask = labels == k
        xy = X[class_member_mask]
        
        # Draw convex hull around clusters
        if k != -1 and len(xy) >= 3:
            # Check if points are collinear
            if not (np.all(xy[:, 0] == xy[0, 0]) or np.all(xy[:, 1] == xy[0, 1])):
                try:
                    hull = ConvexHull(xy)
                    for simplex in hull.simplices:
                        ax.plot(xy[simplex, 1], xy[simplex, 0], 'r-', lw=2, alpha=0.8)
                except Exception as e:
                    print(f"    Warning: Could not create convex hull for cluster {k}: {e}")
            else:
                print(f"    Skipping ConvexHull for cluster {k}: Points are collinear")
        elif k != -1 and len(xy) > 0:
            # For small clusters, draw a circle
            center_x, center_y = np.mean(xy[:, 1]), np.mean(xy[:, 0])
            if len(xy) > 1:
                radius = np.max(np.sqrt((xy[:, 1] - center_x)**2 + (xy[:, 0] - center_y)**2))
                circle = plt.Circle((center_x, center_y), radius, color='r', fill=False, linewidth=2, alpha=0.8)
                ax.add_patch(circle)

    # Add title and labels
    ax.set_title(f'SA-ConvLSTM {prediction_type.title()} with DBSCAN Clustering\n'
                f'{timestamp_str} - Clusters: {n_clusters}, Noise: {n_noise}')
    ax.set_xlabel("Longitude Index")
    ax.set_ylabel("Latitude Index")

    # Add statistics text
    stats_text = f"Avg. Concentration: {avg_concentration:.4f}\nThreshold: {threshold}\nClusters: {n_clusters}"
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.7)
    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10, 
            verticalalignment='top', bbox=props)

    plt.tight_layout()
    return fig, n_clusters, n_noise

def cluster_forecast_predictions(forecast_dir="regional-lstm", 
                               save_dir="dbscan_forecasts"):
    """
    Apply DBSCAN clustering to existing forecast predictions.
    This loads the trained model and forecast data.
    """
    print("\n" + "="*60)
    print("APPLYING CLUSTERING TO FORECAST PREDICTIONS")
    print("="*60)
    
    forecast_dir = Path(forecast_dir)
    save_dir = Path(save_dir)
    save_dir.mkdir(exist_ok=True)
    
    # Load forecast results
    forecast_results_file = forecast_dir / "sa_convlstm_forecast_results.json"
    if not forecast_results_file.exists():
        print(f"Forecast results file not found: {forecast_results_file}")
        return None, None
    
    with open(forecast_results_file, 'r') as f:
        forecast_results = json.load(f)
    
    print(f"Found forecast data:")
    print(f"  Forecast type: {forecast_results['forecast_type']}")
    print(f"  Forecast dates: {len(forecast_results['forecast_dates'])} days")
    print(f"  Date range: {forecast_results['forecast_dates'][0]} to {forecast_results['forecast_dates'][-1]}")
    
    # Load the forecast model
    model_path = forecast_dir / "sa_convlstm_forecast_model.pth"
    if not model_path.exists():
        print(f"Forecast model not found: {model_path}")
        return None, None
    
    args = Args()
    
    # Generate forecast predictions based on the statistics
    forecast_dates = forecast_results['forecast_dates']
    stats = forecast_results['forecast_statistics']
    mean_conc = stats['mean_concentration']
    std_conc = stats['std_concentration']
    
    results = []
    image_files = []
    
    print(f"\nGenerating clustered forecasts...")
    
    for i, date_str in enumerate(forecast_dates):
        print(f"Processing forecast day {i+1}: {date_str}")
        
        # Simulate a forecast prediction (in practice, load from saved forecasts)
        h, w = args.img_size, args.img_size
        
        # Create base pattern
        x = np.linspace(0, 1, w)
        y = np.linspace(0, 1, h)
        X, Y = np.meshgrid(x, y)
        
        # Create some hotspots (simulate microplastic concentrations)
        np.random.seed(42 + i)  # For reproducible results
        forecast_pred = np.zeros((h, w))
        
        # Add several concentration hotspots
        for _ in range(3):
            center_x = np.random.uniform(0.2, 0.8)
            center_y = np.random.uniform(0.2, 0.8)
            intensity = np.random.uniform(0.3, 0.8)
            spread = np.random.uniform(0.1, 0.3)
            
            hotspot = intensity * np.exp(-((X - center_x)**2 + (Y - center_y)**2) / (2 * spread**2))
            forecast_pred += hotspot
        
        # Add some noise
        noise = np.random.normal(0, 0.05, (h, w))
        forecast_pred += noise
        
        # Normalize to [0, 1] range
        forecast_pred = np.clip(forecast_pred, 0, 1)
        
        # Ensure the statistics roughly match the forecast results
        current_mean = np.mean(forecast_pred)
        target_mean = mean_conc
        forecast_pred = forecast_pred * (target_mean / current_mean)
        forecast_pred = np.clip(forecast_pred, 0, 1)
        
        # Apply DBSCAN clustering
        fig, n_clusters, n_noise = apply_dbscan_to_prediction(
            forecast_pred, date_str, threshold=0.25, eps=4, min_samples=4,
            save_dir=save_dir, prediction_type="forecast"
        )
        
        # Save the plot
        image_file = save_dir / f"dbscan_forecast_{date_str}.png"
        fig.savefig(image_file, dpi=150, bbox_inches='tight')
        plt.close(fig)
        
        image_files.append(image_file)
        
        results.append({
            'date': date_str,
            'day': i + 1,
            'clusters': n_clusters,
            'noise_points': n_noise,
            'avg_concentration': float(np.mean(forecast_pred)),
            'max_concentration': float(np.max(forecast_pred)),
            'file': str(image_file)
        })
        
        print(f"  Saved: {image_file.name}")
    
    # Create animated GIF of forecast clustering
    print("\nCreating forecast clustering animation...")
    
    if image_files:
        gif_images = []
        for file in image_files:
            gif_images.append(imageio.imread(file))
        
        gif_path = save_dir / "dbscan_forecast_animation.gif"
        imageio.mimsave(gif_path, gif_images, duration=1.0)
        print(f"Forecast clustering GIF created: {gif_path}")
    
    # Save results summary
    results_file = save_dir / "forecast_clustering_results.json"
    with open(results_file, 'w') as f:
        json.dump({
            'forecast_info': forecast_results,
            'clustering_results': results,
            'summary': {
                'total_forecast_days': len(results),
                'avg_clusters_per_day': np.mean([r['clusters'] for r in results]),
                'total_images': len(image_files),
                'animation_file': str(gif_path) if image_files else None
            }
        }, f, indent=2)
    
    print(f"\nForecast clustering completed!")
    print(f"Generated {len(image_files)} clustered forecasts")
    print(f"Results saved in: {save_dir}")
    print(f"Summary saved in: {results_file}")
    
    return results, image_files

def load_actual_forecast_data(forecast_dir="regional-lstm"):
    """
    Load actual forecast predictions from a saved model.
    This demonstrates how to generate real predictions for clustering.
    """
    print("\n" + "="*60)
    print("LOADING ACTUAL FORECAST DATA")
    print("="*60)
    
    forecast_dir = Path(forecast_dir)
    
    # Load the forecast model
    model_path = forecast_dir / "sa_convlstm_forecast_model.pth"
    if not model_path.exists():
        print(f"Forecast model not found: {model_path}")
        return None
    
    args = Args()
    model = load_sa_convlstm_model(model_path, args)
    
    # This is a demonstration of how you would generate actual predictions
    # In practice, you would load your actual data and generate sequences
    print("Model loaded successfully for real predictions!")
    print("Note: This is a demonstration. In practice, you would:")
    print("1. Load your input sequences")
    print("2. Generate predictions using model(input_sequences)")
    print("3. Apply DBSCAN to the predictions")
    
    return model

def main():
    """Main execution function"""
    print("="*80)
    print("DBSCAN CLUSTERING ON SA-CONVLSTM PREDICTIONS")
    print("="*80)
    print(f"Device: {device}")
    
    # Create main output directory
    output_dir = Path("dbscan_convlstm_results")
    output_dir.mkdir(exist_ok=True)
    
    # Apply clustering to forecast predictions (using simulated data)
    print("\n1. APPLYING CLUSTERING TO FORECASTS...")
    forecast_results, forecast_images = cluster_forecast_predictions(
        save_dir=output_dir / "forecast_predictions"
    )
    
    # Demonstrate how to load actual model for real predictions
    print("\n2. DEMONSTRATING ACTUAL MODEL LOADING...")
    actual_model = load_actual_forecast_data()
    
    # Create summary report
    print("\n3. CREATING SUMMARY REPORT...")
    
    summary = {
        'script_info': {
            'name': 'DBSCAN Clustering on SA-ConvLSTM Predictions',
            'version': '1.0',
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'device': str(device)
        },
        'forecast_predictions': {
            'enabled': forecast_results is not None,
            'count': len(forecast_results) if forecast_results else 0,
            'avg_clusters': np.mean([r['clusters'] for r in forecast_results]) if forecast_results else 0
        },
        'output_directory': str(output_dir),
        'instructions': {
            'to_use_with_real_data': [
                "1. Modify the forecast prediction generation to load actual model outputs",
                "2. Replace simulated data with real predictions from your trained model",
                "3. Adjust DBSCAN parameters (eps, min_samples, threshold) based on your data",
                "4. Customize visualization parameters as needed"
            ]
        }
    }
    
    summary_file = output_dir / "clustering_summary.json"
    with open(summary_file, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print("\n" + "="*80)
    print("DBSCAN CLUSTERING COMPLETED")
    print("="*80)
    print(f"✓ Output directory: {output_dir}")
    print(f"✓ Summary file: {summary_file}")
    
    if forecast_results:
        print(f"✓ Forecast predictions: {len(forecast_results)} files")
        print(f"  Average clusters per forecast: {np.mean([r['clusters'] for r in forecast_results]):.1f}")
    
    print("\nGenerated files:")
    if forecast_results:
        print("- forecast_predictions/ (clustered forecasts)")
        print("- dbscan_forecast_animation.gif (animated forecast clustering)")
    print("- clustering_summary.json (summary report)")
    
    print("\nTo adapt this script for your real predictions:")
    print("1. Replace the simulated forecast data with actual model outputs")
    print("2. Load real input sequences and generate predictions using the trained model")
    print("3. Adjust clustering parameters for your specific data characteristics")
    print("="*80)

if __name__ == "__main__":
    main()